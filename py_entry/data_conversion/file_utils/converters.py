"""å°†å›æµ‹ç»“æœè½¬æ¢ä¸ºä¸åŒæ ¼å¼çš„buffer"""

import io
import json
from pathlib import Path
from typing import List, Tuple, Optional
import polars as pl

from py_entry.data_conversion.types import (
    BacktestSummary,
    DataContainer,
    ParamContainer,
    TemplateContainer,
    SettingContainer,
)


def _add_index_to_dataframe(df: pl.DataFrame) -> pl.DataFrame:
    """ä¸ºDataFrameæ·»åŠ è¡Œå·ï¼ˆç´¢å¼•ï¼‰åˆ—ä½œä¸ºç¬¬ä¸€åˆ—

    Args:
        df: è¾“å…¥çš„DataFrame

    Returns:
        æ·»åŠ äº†ç´¢å¼•åˆ—çš„DataFrame
    """
    if df.height == 0:
        return df

    # ğŸŒŸ ä½¿ç”¨ with_row_count(name="index", offset=0)
    # å®ƒä¼šè‡ªåŠ¨å°†æ–°åˆ—æ”¾åœ¨ç¬¬ä¸€ä½
    return df.with_row_index(name="index", offset=0)


def _process_dataframe_for_export(df: pl.DataFrame, keep_index: bool) -> pl.DataFrame:
    """å¤„ç†DataFrameä»¥å‡†å¤‡å¯¼å‡ºï¼Œæ ¹æ®éœ€è¦æ·»åŠ ç´¢å¼•

    Args:
        df: è¾“å…¥çš„DataFrame
        keep_index: æ˜¯å¦æ·»åŠ ç´¢å¼•åˆ—

    Returns:
        å¤„ç†åçš„DataFrame
    """
    if keep_index:
        return _add_index_to_dataframe(df)
    return df


def convert_backtest_results_to_buffers(
    results: list[BacktestSummary],
    dataframe_format: str = "csv",
    keep_index: bool = True,
) -> List[Tuple[Path, io.BytesIO]]:
    """å°†å›æµ‹ç»“æœè½¬æ¢ä¸ºbufferåˆ—è¡¨ï¼Œç”¨äºä¿å­˜æˆ–ä¸Šä¼ ã€‚

    Args:
        results: å›æµ‹ç»“æœåˆ—è¡¨
        dataframe_format: DataFrameæ ¼å¼ï¼Œ"csv"æˆ–"parquet"
        keep_index: æ˜¯å¦åœ¨DataFrameçš„ç¬¬ä¸€åˆ—æ·»åŠ æ•´æ•°ç´¢å¼•

    Returns:
        åŒ…å«(è·¯å¾„, BytesIO)å…ƒç»„çš„åˆ—è¡¨
    """
    data_list = []

    for idx, summary in enumerate(results):
        # å¦‚æœæœ‰å¤šä¸ªç»“æœï¼Œæ·»åŠ å­ç›®å½•å‰ç¼€
        prefix = f"run_{idx}/" if len(results) > 1 else ""

        # Performance (dict -> JSON)
        if summary.performance:
            json_bytes = json.dumps(
                summary.performance, indent=2, ensure_ascii=False
            ).encode("utf-8")
            data_list.append(
                (Path(f"{prefix}performance.json"), io.BytesIO(json_bytes))
            )

        # Indicators (dict[str, DataFrame])
        if summary.indicators:
            for key, df in summary.indicators.items():
                processed_df = _process_dataframe_for_export(df, keep_index)
                buf = io.BytesIO()
                if dataframe_format == "csv":
                    processed_df.write_csv(buf)
                else:
                    processed_df.write_parquet(buf)
                data_list.append(
                    (Path(f"{prefix}indicators_{key}.{dataframe_format}"), buf)
                )

        # Signals (DataFrame)
        if summary.signals is not None:
            processed_df = _process_dataframe_for_export(summary.signals, keep_index)
            buf = io.BytesIO()
            if dataframe_format == "csv":
                processed_df.write_csv(buf)
            else:
                processed_df.write_parquet(buf)
            data_list.append((Path(f"{prefix}signals.{dataframe_format}"), buf))

        # Backtest Result (DataFrame)
        if summary.backtest_result is not None:
            processed_df = _process_dataframe_for_export(
                summary.backtest_result, keep_index
            )
            buf = io.BytesIO()
            if dataframe_format == "csv":
                processed_df.write_csv(buf)
            else:
                processed_df.write_parquet(buf)
            data_list.append((Path(f"{prefix}backtest_result.{dataframe_format}"), buf))

    return data_list


def convert_all_backtest_data_to_buffers(
    data_dict: Optional[DataContainer],
    param_set: Optional[ParamContainer],
    template_config: Optional[TemplateContainer],
    engine_settings: Optional[SettingContainer],
    results: list[BacktestSummary],
    dataframe_format: str = "csv",
    keep_index: bool = True,
) -> List[Tuple[Path, io.BytesIO]]:
    """å°†æ‰€æœ‰å›æµ‹æ•°æ®ï¼ˆåŒ…æ‹¬é…ç½®å’Œç»“æœï¼‰è½¬æ¢ä¸ºbufferåˆ—è¡¨ï¼Œç”¨äºä¿å­˜æˆ–ä¸Šä¼ ã€‚

    Args:
        data_dict: æ•°æ®å®¹å™¨
        param_set: å‚æ•°å®¹å™¨
        template_config: æ¨¡æ¿é…ç½®å®¹å™¨
        engine_settings: å¼•æ“è®¾ç½®å®¹å™¨
        results: å›æµ‹ç»“æœåˆ—è¡¨
        dataframe_format: DataFrameæ ¼å¼ï¼Œ"csv"æˆ–"parquet"
        keep_index: æ˜¯å¦åœ¨DataFrameçš„ç¬¬ä¸€åˆ—æ·»åŠ æ•´æ•°ç´¢å¼•

    Returns:
        åŒ…å«(è·¯å¾„, BytesIO)å…ƒç»„çš„åˆ—è¡¨
    """
    data_list = []

    # 1. è½¬æ¢å›æµ‹ç»“æœï¼ˆä½¿ç”¨ç°æœ‰å‡½æ•°ï¼‰
    result_buffers = convert_backtest_results_to_buffers(
        results, dataframe_format, keep_index
    )
    prefixed_result_buffers = [
        (Path("backtest_results") / path, buffer) for path, buffer in result_buffers
    ]
    data_list.extend(prefixed_result_buffers)

    # 2. è½¬æ¢æ•°æ®å­—å…¸
    if data_dict is not None:
        # mapping (DataFrame)
        if data_dict.mapping is not None:
            processed_df = _process_dataframe_for_export(data_dict.mapping, keep_index)
            buf = io.BytesIO()
            if dataframe_format == "csv":
                processed_df.write_csv(buf)
            else:
                processed_df.write_parquet(buf)
            data_list.append((Path("data_dict/mapping.csv"), buf))

        # skip_mask (Series)
        if data_dict.skip_mask is not None:
            skip_mask_df = data_dict.skip_mask.to_frame()
            processed_df = _process_dataframe_for_export(skip_mask_df, keep_index)
            buf = io.BytesIO()
            if dataframe_format == "csv":
                processed_df.write_csv(buf)
            else:
                processed_df.write_parquet(buf)
            data_list.append((Path("data_dict/skip_mask.csv"), buf))

        # skip_mapping (dict)
        if data_dict.skip_mapping is not None:
            json_bytes = json.dumps(
                data_dict.skip_mapping, indent=2, ensure_ascii=False
            ).encode("utf-8")
            data_list.append(
                (Path("data_dict/skip_mapping.json"), io.BytesIO(json_bytes))
            )

        # source (dict[str, DataFrame])
        if data_dict.source is not None:
            for key, df in data_dict.source.items():
                processed_df = _process_dataframe_for_export(df, keep_index)
                buf = io.BytesIO()
                if dataframe_format == "csv":
                    processed_df.write_csv(buf)
                else:
                    processed_df.write_parquet(buf)
                data_list.append(
                    (Path(f"data_dict/source_{key}.{dataframe_format}"), buf)
                )

        # BaseDataKey (str)
        if data_dict.BaseDataKey is not None:
            json_bytes = json.dumps(
                {"BaseDataKey": data_dict.BaseDataKey}, indent=2, ensure_ascii=False
            ).encode("utf-8")
            data_list.append(
                (Path("data_dict/base_data_key.json"), io.BytesIO(json_bytes))
            )

    # 3. è½¬æ¢å‚æ•°é›†
    if param_set is not None:
        param_list = []
        for i, single_param in enumerate(param_set):
            param_dict = {
                "indicators": single_param.indicators,
                "signal": single_param.signal,
                "backtest": single_param.backtest.__dict__,
                "performance": {
                    "metrics": [
                        metric.value for metric in single_param.performance.metrics
                    ]
                },
            }
            param_list.append(param_dict)

        json_bytes = json.dumps(
            param_list, indent=2, ensure_ascii=False, default=str
        ).encode("utf-8")
        data_list.append((Path("param_set/param_set.json"), io.BytesIO(json_bytes)))

    # 4. è½¬æ¢æ¨¡æ¿é…ç½®
    if template_config is not None:
        template_dict = {
            "name": template_config.signal.name,
            "enter_long": template_config.signal.enter_long,
            "exit_long": template_config.signal.exit_long,
            "enter_short": template_config.signal.enter_short,
            "exit_short": template_config.signal.exit_short,
        }
        json_bytes = json.dumps(
            template_dict, indent=2, ensure_ascii=False, default=str
        ).encode("utf-8")
        data_list.append(
            (Path("template_config/template_config.json"), io.BytesIO(json_bytes))
        )

    # 5. è½¬æ¢å¼•æ“è®¾ç½®
    if engine_settings is not None:
        settings_dict = {
            "execution_stage": engine_settings.execution_stage.value,
            "return_only_final": engine_settings.return_only_final,
        }
        json_bytes = json.dumps(
            settings_dict, indent=2, ensure_ascii=False, default=str
        ).encode("utf-8")
        data_list.append(
            (Path("engine_settings/engine_settings.json"), io.BytesIO(json_bytes))
        )

    return data_list
