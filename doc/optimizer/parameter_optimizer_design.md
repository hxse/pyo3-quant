# 参数优化器设计文档

> **核心目标**：为三重滤网等中短线策略提供高并发、自适应的参数优化能力，支持向前滚动优化，避免参数过拟合。

---

## 1. 模块解耦设计

本模块分为两个独立但可组合的部分：

| 模块 | 职责 | 可独立使用 |
|------|------|------------|
| **参数优化器（Optimizer）** | 单次参数搜索，找到最优参数组合 | ✅ |
| **向前滚动引擎（WalkForward）** | 多窗口滚动，调用优化器，验证样本外表现 | ✅ |

**组合使用**：向前滚动引擎在每个窗口调用优化器，并传递窗口间的权重继承信息。

**独立使用**：
- 只用优化器：单次全量回测优化
- 只用向前滚动：固定参数，只做时间切分验证

---

# Part A：参数优化器（Optimizer）

## 2. 设计理念

### 2.1 追求并发效率优先

- **放弃贝叶斯优化**：虽然样本效率高，但存在顺序依赖性（每次采样依赖前次结果），无法充分并行
- **放弃遗传算法的代际同步**：每一代必须等上一代完成，限制并发度
- **选择权重驱动的随机搜索**：每轮采样点完全独立，可跑满所有 CPU 核心

### 2.2 简单优于复杂

- 调参参数越少越好，避免"优化器本身需要调参"的元问题
- 所有参数都暴露，但**建议只调整探索比例**，其他用默认值

### 2.3 与交易哲学一致

- 向前滚动优化解决**参数过拟合**问题
- 策略逻辑过拟合不在优化器职责范围内（由策略设计本身保证）
- 短生命周期策略 + 动态迭代 = 不追求"万金油"参数

---

## 3. 核心架构

### 3.1 参数定义

```rust
pub struct Param {
    /// 参数最小值限制
    pub min: f64,
    /// 参数最大值限制
    pub max: f64,
    /// 数据类型：Integer, Float, Boolean
    pub dtype: ParamType,
    /// 是否在对数空间采样（适合 SMA 周期等参数）
    pub log_scale: bool,
    /// 是否参与优化
    pub optimize: bool,
    /// 是否开启对数分布，用于参数优化时的采样策略
    pub log_scale: bool,
    /// 最小精度（步长）
    pub step: f64,
}
```

**精度控制（Step）**：
- **钝化噪音**：通过设置 `step`（如均线周期为 5, ATR 倍数为 0.5），可以强迫优化器在具有物理意义的网格上搜索。
- **提高稳定性**：防止由于参数微小波动（如 20.001 vs 20.002）导致的由于回测噪音引起的绩效剧烈变化。
- **默认行为**：Python 装饰器会自动推断默认步长（Integer 默认为 1.0, Float 默认为 0.1）。

### 3.2 采样策略：混合采样

每次采样由两部分组成：

```
采样分布 = (1 - explore_ratio) × 权重驱动采样 + explore_ratio × 全局 LHS 采样
              ↓                                         ↓
         聚焦历史最优区域                           均匀覆盖整个参数空间
```

这个固定比例是防止过度收敛的核心机制——无论权重多么集中，探索部分的采样始终均匀覆盖整个参数空间。

### 3.3 参数量化（Quantization）

所有采样点（无论是 LHS 还是权重采样）在进入回测引擎前，都会按照下式进行量化：

```rust
fn quantize(val: f64, step: f64) -> f64 {
    if step > 0.0 { (val / step).round() * step } else { val }
}
```

量化保证了优化器返回的“最佳参数”是离散且可直接用于实盘配置的。

---

## 4. 采样方法详解

### 4.1 Latin Hypercube Sampling (LHS)

**作用**：让采样点在每个维度上都均匀分布，比纯随机采样覆盖更全。

**原理**：
- 把每个维度切成 N 等份（N = 采样次数）
- 每个区间只采样一次
- 不同维度的区间随机配对

**与对数分布的兼容**（先 LHS 再对数变换）：
1. LHS 生成 `[0, 1]` 均匀分布的点
2. 用逆 CDF 变换映射到目标分布
3. 对于 `log_scale=true`：`value = exp(log_min + u × (log_max - log_min))`

### 4.2 权重驱动采样（高斯核密度）

**输入**：上一轮/上一窗口的 Top K 个最优参数组合及其性能排名

**权重分配**：按排名指数衰减（衰减系数由 `weight_decay` 参数控制）
- 第 1 名权重：1.0
- 第 i 名权重：e^(-weight_decay × i)

**采样过程**：
1. 为每个 Top K 的参数值放置一个高斯核
2. 核的权重 = 排名权重
3. 核的标准差 σ = (max - min) × `sigma_ratio`
4. 叠加所有高斯核，得到总概率密度
5. 按此密度采样

**对数空间处理**：
- 对于 `log_scale=true` 的参数，先转换到对数空间
- 在对数空间计算高斯核
- 采样后用 `exp()` 变换回原空间

---

## 5. 迭代与停止机制

### 5.1 单次优化的迭代

```
第 1 轮：100% LHS 全局采样（无历史先验）
       → 得到 Top K，计算权重分布

第 2 轮：(1 - explore_ratio) 权重采样 + explore_ratio LHS
       → 得到新 Top K，更新权重分布

第 3 轮：同上
       → ...

停止条件：触发任一停止规则
```

### 5.2 停止条件

采用**“无新高停止”**（Patience-based Stopping）机制：

如果连续 `stop_patience` 轮（默认 10 轮）全局最优指标（如 Calmar 比率）没有创出新高，则智能判断为已收敛，停止迭代。

为防止过早停止，设有基础保护机制：
- **最小采样保护**：采样总数未达到 `min_samples`（默认 400）时不检查停止。

---

## 6. 对数分布参数的处理

### 6.1 为什么需要对数分布

某些参数（如 SMA 周期）对小值更敏感：
- SMA_5 → SMA_10：翻倍变化，影响大
- SMA_50 → SMA_55：10% 变化，影响小

用对数分布采样可以让小值区域采样更密。

### 6.2 统一处理方式（先采样再变换）

1. **LHS 采样**：生成 `[0, 1]` 均匀分布的点
2. **逆 CDF 变换**：对于 `log_scale=true`，用 `exp(log_min + u × (log_max - log_min))` 变换
3. **高斯核权重采样**：在对数空间计算高斯核，采样后用 `exp()` 变换回原空间

这样对数分布与其他采样机制完美兼容。

---

## 7. 优化器参数汇总

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `explore_ratio` | 0.30 | 全局 LHS 采样的占比，防止过度收敛 |
| `sigma_ratio` | 0.15 | 高斯核标准差占参数范围的比例 |
| `weight_decay` | 0.10 | 排名权重的指数衰减系数 |
| `top_k_ratio` | 0.70 | 每轮保留的最优参数组合比例（相对于采样数） |
| `samples_per_round` | 100 | 每轮迭代的采样点数 |
| `max_samples` | 10000 | 最大采样点数，避免无法收敛时无限循环 |
| `min_samples` | 400 | 最小采样点数（在检查停止条件前必须达到的采样数） |
| `max_rounds` | 200 | 最大迭代轮数 |
| `stop_patience` | 10 | 连续多少轮无新高则停止 |
| `optimize_metric` | `CalmarRatioRaw` | 优化目标指标（支持 Sharpe, Sortino, Calmar 等） |
| `init_samples` | `None` | (可选) 初始采样点列表，用于注入先验知识（如 Walk Forward 继承） |

> **建议**：只调整 `explore_ratio`，其他参数使用默认值即可。

---

# Part B：向前滚动引擎（WalkForward）

## 8. 窗口结构

```
窗口1: [1-6] 训练 → [7-8] 测试
窗口2: [2-7] 训练 → [8-9] 测试
窗口3: [3-8] 训练 → [9-10] 测试
...
```

窗口数据切分由参数控制：训练期长度、过渡期长度、测试期长度可配置。
滚动步长为硬约束：固定等于测试期长度（不支持独立步长参数）。

---

## 9. 窗口间权重继承

```
窗口 N 的采样先验 = 窗口 N-1 的 Top K 分布
```

**设计选择**：只继承上一窗口，不累积更早历史
- 更简单，无需管理历史权重衰减
- 自然带有"遗忘"能力，适应市场变化
- 如果某窗口表现差，不会污染后续太久

### 9.1 冷启动

第一个窗口没有先验，使用 100% LHS 全局采样。

### 9.2 防止过度收敛

通过固定的探索比例保证：
- 即使继承的权重高度集中，仍有采样点覆盖边缘区域
- 如果市场结构变化，新的好参数会通过全局探索被发现

---

## 10. 向前滚动参数汇总

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `train_ratio` | 0.60 | 训练窗口长度（占总数据长度的比例） |
| `transition_ratio` | 0.10 | 过渡窗口长度（占总数据长度的比例） |
| `test_ratio` | 0.20 | 测试窗口长度（占总数据长度的比例） |
| `inherit_prior` | true | 是否从上一窗口继承权重先验 |

> **建议**：根据数据量和策略类型调整 `train_ratio` 和 `test_ratio`，其他使用默认值。

---

## 11. 长线持仓说明

本优化器专为中短线策略设计，**不处理**长线持仓的窗口切换仓位问题。

如需长线策略优化，建议使用二分法/三分法定位最优参数，配合参数抖动测试验证稳健性。

---

## 12. 与其他优化方法的对比

| 维度 | 本方案 | 遗传算法 | 贝叶斯优化 |
|------|--------|----------|------------|
| **并发度** | ⭐⭐⭐ 极高 | ⭐⭐ 中等 | ⭐ 低 |
| **样本效率** | ⭐⭐ 中等 | ⭐⭐ 中等 | ⭐⭐⭐ 高 |
| **高维表现** | ⭐⭐ 中等 | ⭐⭐ 中等 | ⭐ 差 |
| **实现复杂度** | ⭐ 简单 | ⭐⭐ 中等 | ⭐⭐⭐ 复杂 |
| **窗口继承** | ⭐⭐⭐ 天然支持 | ⭐⭐ 可实现 | ⭐⭐ 可实现 |

**选择本方案的理由**：
- 回测速度快（1 万 K 线 ~0.06s），样本效率不是瓶颈
- 10+ 参数在中维范围，三种方法差别不大
- 向前滚动优化需要窗口继承，本方案天然支持
- 追求简单可控，避免调优化器参数

---

## 13. 依赖库

| 库 | 用途 | 是否必须 |
|----|------|----------|
| `rand`, `rand_distr` | 随机数生成、分布采样 | ✅ 是 |
| `polars` | 结果存储和分析 | ✅ 已有 |
| `lhs` crate | Latin Hypercube Sampling | ✅ 使用现有库 |
| `statrs` | 分位数、统计函数 | ⚪ 可选 |

---

## 14. 总结

本参数优化器的核心特征：

1. **模块解耦**：优化器和向前滚动引擎可独立使用或组合使用
2. **极致并发**：每轮采样点完全独立，无顺序依赖
3. **权重驱动**：聚焦历史最优区域，同时保留全局探索
4. **窗口继承**：只记住上一窗口，自然遗忘远古历史
5. **对数兼容**：在对数空间统一处理敏感参数
6. **精度控制**：引入 `step` 机制钝化参数噪音，提高优化结果的稳健型
7. **参数透明**：所有参数暴露可调，但建议只调整探索比例

这套设计与交易哲学一致：追求效率、接受策略失效、动态迭代。
